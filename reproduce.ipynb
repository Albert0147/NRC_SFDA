{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import argparse\r\n",
    "import os, sys\r\n",
    "import os.path as osp\r\n",
    "import torchvision\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "from torchvision import transforms\r\n",
    "import network, loss\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from data_list import ImageList, ImageList_idx\r\n",
    "import random, pdb, math, copy\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "import torch.nn.functional as F\r\n",
    "from train_tar import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "parser = argparse.ArgumentParser(description='Neighbors')\r\n",
    "parser.add_argument('--gpu_id',\r\n",
    "                    type=str,\r\n",
    "                    nargs='?',\r\n",
    "                    default='1',\r\n",
    "                    help=\"device id to run\")\r\n",
    "parser.add_argument('--s', type=int, default=0, help=\"source\")\r\n",
    "parser.add_argument('--t', type=int, default=1, help=\"target\")\r\n",
    "parser.add_argument('--max_epoch',\r\n",
    "                    type=int,\r\n",
    "                    default=15,\r\n",
    "                    help=\"max iterations\")\r\n",
    "parser.add_argument('--interval', type=int, default=15)\r\n",
    "parser.add_argument('--batch_size',\r\n",
    "                    type=int,\r\n",
    "                    default=64,\r\n",
    "                    help=\"batch_size\")\r\n",
    "parser.add_argument('--worker',\r\n",
    "                    type=int,\r\n",
    "                    default=4,\r\n",
    "                    help=\"number of workers\")\r\n",
    "parser.add_argument(\r\n",
    "    '--dset',\r\n",
    "    type=str,\r\n",
    "    default='visda-2017')\r\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help=\"learning rate\")\r\n",
    "parser.add_argument('--net',\r\n",
    "                    type=str,\r\n",
    "                    default='resnet101')\r\n",
    "parser.add_argument('--seed', type=int, default=2021, help=\"random seed\")\r\n",
    "\r\n",
    "parser.add_argument('--bottleneck', type=int, default=256)\r\n",
    "parser.add_argument('--K', type=int, default=5)\r\n",
    "parser.add_argument('--KK', type=int, default=5)\r\n",
    "parser.add_argument('--epsilon', type=float, default=1e-5)\r\n",
    "parser.add_argument('--layer',\r\n",
    "                    type=str,\r\n",
    "                    default=\"wn\",\r\n",
    "                    choices=[\"linear\", \"wn\"])\r\n",
    "parser.add_argument('--classifier',\r\n",
    "                    type=str,\r\n",
    "                    default=\"bn\",\r\n",
    "                    choices=[\"ori\", \"bn\"])\r\n",
    "parser.add_argument('--output', type=str, default='weight/target/')\r\n",
    "parser.add_argument('--output_src', type=str, default='weight/source/')\r\n",
    "parser.add_argument('--tag', type=str, default='noself')\r\n",
    "parser.add_argument('--da',\r\n",
    "                    type=str,\r\n",
    "                    default='uda')\r\n",
    "parser.add_argument('--issave', type=bool, default=True)\r\n",
    "args = parser.parse_args([])\r\n",
    "\r\n",
    "if args.dset == 'office-home':\r\n",
    "    names = ['Art', 'Clipart', 'Product', 'RealWorld']\r\n",
    "    args.class_num = 65\r\n",
    "if args.dset == 'visda-2017':\r\n",
    "    names = ['train', 'validation']\r\n",
    "    args.class_num = 12\r\n",
    "\r\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id\r\n",
    "SEED = args.seed\r\n",
    "torch.manual_seed(SEED)\r\n",
    "torch.cuda.manual_seed(SEED)\r\n",
    "np.random.seed(SEED)\r\n",
    "random.seed(SEED)\r\n",
    "torch.backends.cudnn.deterministic = True\r\n",
    "\r\n",
    "for i in range(len(names)):\r\n",
    "    if i == args.s:\r\n",
    "        continue\r\n",
    "    args.t = i\r\n",
    "\r\n",
    "    folder = './data/'\r\n",
    "    args.s_dset_path = folder + args.dset + '/' + names[\r\n",
    "        args.s] + '_list.txt'\r\n",
    "    args.t_dset_path = folder + args.dset + '/' + names[\r\n",
    "        args.t] + '_list.txt'\r\n",
    "    args.test_dset_path = folder + args.dset + '/' + names[\r\n",
    "        args.t] + '_list.txt'\r\n",
    "\r\n",
    "    args.output_dir_src = osp.join(args.output_src, args.da, args.dset,\r\n",
    "                                    names[args.s][0].upper())\r\n",
    "    args.output_dir = osp.join(\r\n",
    "        args.output, args.da, args.dset,\r\n",
    "        names[args.s][0].upper() + names[args.t][0].upper())\r\n",
    "    args.name = names[args.s][0].upper() + names[args.t][0].upper()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "dset_loaders = data_load(args)\r\n",
    "## set base network\r\n",
    "netF = network.ResBase(res_name=args.net).cuda()\r\n",
    "\r\n",
    "netB = network.feat_bootleneck(type=args.classifier,\r\n",
    "                                feature_dim=netF.in_features,\r\n",
    "                                bottleneck_dim=args.bottleneck).cuda()\r\n",
    "netC = network.feat_classifier(type=args.layer,\r\n",
    "                                class_num=args.class_num,\r\n",
    "                                bottleneck_dim=args.bottleneck).cuda()\r\n",
    "\r\n",
    "modelpath = args.output_dir + '/target_F_tar_5.pt'\r\n",
    "netF.load_state_dict(torch.load(modelpath))\r\n",
    "modelpath = args.output_dir + '/target_B_tar_5.pt'\r\n",
    "netB.load_state_dict(torch.load(modelpath))\r\n",
    "modelpath = args.output_dir + '/target_C_tar_5.pt'\r\n",
    "netC.load_state_dict(torch.load(modelpath))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "netF.eval()\r\n",
    "netB.eval()\r\n",
    "netC.eval()\r\n",
    "if args.dset == 'visda-2017':\r\n",
    "    acc_s_te, acc_list = cal_acc(dset_loaders['test'], netF, netB,\r\n",
    "                                    netC,flag= True)\r\n",
    "print(acc_s_te)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "eb1af71eac2c222774c10995b6079cc7d9ae7c6616d6273f176c99612b4554b8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}